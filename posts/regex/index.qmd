---
title: "Using regular expressions to deal with dirty data in `R`"
date: "2022-11-24"
categories: [core essential, regex]
image: "oliver-hale-oTvU7Zmteic-unsplash.jpg"
code-fold: false
draft: true
---

::: column-page
## How to start cleaning data by using regular expressions

Check out how to use regular expressions to clean up a realistic and dirty customer dataset.

Dirty data can seem extremely overwhelming at times, but breaking it down into cleaning "stages" is how I approach the task.

### Packages

I will be using the [`tidyverse`](https://tidyverse.tidyverse.org/), [`janitor`](https://sfirke.github.io/janitor/) and [`skimr`](https://docs.ropensci.org/skimr/index.html) packages; you can install and load these packages with the following code:

-   Install packages

    ``` r
    install.packages("tidyverse")
    install.packages("janitor")
    install.packages("skimr")
    ```

-   Load packages

    ``` r
    library(tidyverse)
    library(janitor)
    library(skimr)
    ```

```{r}
#| warning: false
#| message: false
#| include: false
library(tidyverse)
library(janitor)
library(skimr)

# load in customer data
  # library(vroom)
  # customers <- vroom("customers.csv") %>%
  #   clean_names() %>%
  #   select(customer, main_phone, main_email)
  # 
  # write_csv(customers, "customers-dirty.csv")
```

### Import the data

Once you load in your packages, you can read in your data. In this case I am loading in a local `.csv` file, and because `tidyverse` is loaded in, we can use the `read_csv()` function from the `readr` package.

You can also use the `vroom` package instead of `readr` if you have a large dataset and want to save on resources. *see `vroom`[documentation](https://vroom.r-lib.org/)*

```{r}
#| warning: false
#| message: false
  customers <- read_csv("customers-dirty.csv")
  
  head(customers)
  
  customers %>%
    skim()
```
:::
