{
  "hash": "9c4906f9cfd4bdeda34d4c9c1f21b98b",
  "result": {
    "markdown": "---\ntitle: \"Using regular expressions to deal with dirty data in `R`\"\ndate: \"2022-11-24\"\ncategories: [core essential, regex]\nimage: \"oliver-hale-oTvU7Zmteic-unsplash.jpg\"\ncode-fold: false\ndraft: true\n---\n\n\n::: column-page\n## How to start cleaning data by using regular expressions\n\nCheck out how to use regular expressions to clean up a realistic and dirty customer dataset.\n\n> Dirty data can seem extremely overwhelming at times, but breaking it down into cleaning \"stages\" is how I approach the task.\n\n### Packages\n\nI will be using the [`tidyverse`](https://tidyverse.tidyverse.org/), [`janitor`](https://sfirke.github.io/janitor/) and [`skimr`](https://docs.ropensci.org/skimr/index.html) packages; you can install and load these packages with the following code:\n\n-   Install packages\n\n    ``` r\n    install.packages(\"tidyverse\")\n    install.packages(\"janitor\")\n    install.packages(\"skimr\")\n    ```\n\n-   Load packages\n\n    ``` r\n    library(tidyverse)\n    library(janitor)\n    library(skimr)\n    ```\n\n<br>\n\n\n\n\n\n### Import the data\n\nOnce you load in your packages, you can read in your data. In this case I am loading in a local `.csv` file, and because `tidyverse` is loaded in, we can use the `read_csv()` function from the `readr` package.\n\nYou can also use the `vroom` package instead of `readr` if you have a large dataset and want to save on resources.\n\n> *see `vroom`[documentation](https://vroom.r-lib.org/)*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  customers <- read_csv(\"customers-dirty.csv\")\n```\n:::\n\n\nIf your data has dirty column headers, such as spaces, case inconsistencies, and more then use the `janitor` package to clean them up when you import your data.\n\nAll you have to do is add a `pipe` aka '`%>%`' at the end of your `read_csv()` or `vroom()` line, and this will tell R to pipe everything into the following function. On the next line add in the `clean_names()` function like below, and `janitor` will clean up the column headers for you!\n\n``` r\n  customers <- read_csv(\"customers-dirty.csv\") %>%\n    clean_names()\n```\n\n<br>\n\n## Evaluating the data\n\n### What is clean data?\n\nNow that we have our packages and the data loaded into `R`, it is time to begin cleaning. But before I look at the records, I want to look at the column headers and \"*picture*\" what a clean record would look like.\n\nFor example I created this table that shows the columns of this data set, with specific \"rules\" for the data and cleaned examples.\n\nThe \"cleaned example\" is just an example of a record after cleaning, so when working on a project for a stakeholder your cleaning is relative to their needs.\n\n| Column     | Type      | Description                                                        | Cleaned Example         |\n|------------------|------------------|------------------|------------------|\n| customer   | character | customer name, proper case, valid names, no addresses              | John Smith              |\n| main_phone | numeric   | phone number, valid 10 digits, no spaces or non-numeric characters | 1112223333              |\n| main_email | character | email address, no spaces, valid addresses                          | john.smith\\@example.com |\n\n<br>\n\n### Cleaning steps\n\nNow that we know what the output has to be we can methodically wrangle and clean the input data with a series of \"steps\".\n\nLets take a quick peek at the data and see what we are working with, using the `skimr` package.\n\n> The `skim()` function can take a tibble or an object that can be coerced into a tibble, and returns a quick broad overview of a data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  skim()\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |Piped data |\n|Number of rows           |15135      |\n|Number of columns        |3          |\n|_______________________  |           |\n|Column type frequency:   |           |\n|character                |3          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|customer      |         0|          1.00|   3|  99|     0|    15135|          0|\n|main_phone    |      2000|          0.87|  10|  43|     0|     3272|          0|\n|main_email    |      2243|          0.85|   3|  99|     0|     2707|          0|\n:::\n:::\n\n\nWe can see in this overview that there are over 15,000 rows and \"unique\" records in the customer column, however just about 3,300 unique main_phone and 2,700 main_email records. But these columns are only missing \\~2,000 - 2,300 records, and not a more anticipated \\~12,000 or other large value.\n\nThis means we are going to be dealing with duplicates in addition to formatting and cleaning the individual records.\n\nNow lets take a peek at the records finally...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(customers,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 3\n   customer                                         main_phone         main_em~1\n   <chr>                                            <chr>              <chr>    \n 1 *JESUS SANCHEZ                                   9670-342-6100      <NA>     \n 2 *JESUS SANCHEZ:17900 CR 5                        9670-342-6100      <NA>     \n 3 1888 INDUSTRIAL SERVICES                         970-702-7610       AP@1888I~\n 4 1888 INDUSTRIAL SERVICES:WELLS RANCH TO REPUBLIC 970-702-7610       AP@1888I~\n 5 2 RINGS TRUCKING                                 406-289-0901       <NA>     \n 6 2 RINGS TRUCKING:35094 CR 51, EATON              406-289-0901       <NA>     \n 7 2 VALLEY BUILDERS, INC                           970-599-2134- John 2valleyb~\n 8 2 VALLEY BUILDERS, INC:1106 COYOTE LANE          970-599-2134- John 2valleyb~\n 9 2 VALLEY BUILDERS, INC:15101 MCR 7.3, WIGGINS    970-599-2134- John 2valleyb~\n10 2 VALLEY BUILDERS, INC:15207 MCR 7.3, WIGGINS    970-599-2134- John 2valleyb~\n# ... with abbreviated variable name 1: main_email\n```\n:::\n:::\n\n\nAs we can see, there is the head of the dirty data, and duplicates we will be fixing.\n\n<br>\n\n#### Cleaning phone numbers\n\nIn order to \"clean\" the phone numbers we will remove any non-numeric characters, spaces, symbols, and even check the numbers. I want the numbers to be 10 digits long, and any additional numbers will be moved into a new column called `possible_ext` and it will represent the possible phone number extension digits commonly needed to reach specific phones within a network.\n\nMy logic behind this is that for a record with more numbers than 10, there was either an issue with the data entry or it is a valid extension. Either way all the numbers are present and if a couple records have errors it is okay, because we can update them in the future if the number was entered incorrectly or with extra characters.\n\nI will be using the `str_trim()` function to remove white space on either side of the phone numbers in the data. For help on regex you can view this [cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf) for the `stringr` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nphone_numbers <- customers %>%\n  drop_na(main_phone)\n\n# trim white space from both sides\nphone_numbers$main_phone <- str_trim(phone_numbers$main_phone, side = c(\"both\"))\n\n# gsub()\nphone_numbers$main_phone <- gsub(\"[a-zA-Z]+\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"-\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\.\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\_\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\:\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\*\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\(\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\)\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\s_ \", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"/ \", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\" \", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"@\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\s\", \"\", phone_numbers$main_phone)\nphone_numbers$main_phone <- gsub(\"\\\\\\ \", \"\", phone_numbers$main_phone)\n\n\n# trim white space from both sides\nphone_numbers$main_phone <- str_trim(phone_numbers$main_phone)\n\n# write_csv(phone_numbers, \"phone-numbers.csv\")\n\nphone_numbers_2 <- read_csv(\"phone-numbers.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 13135 Columns: 4\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (4): customer, main_phone, main_email, main_phone_e\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nphone_numbers_2$main_phone_e <- gsub(\"/\", \"\", phone_numbers_2$main_phone_e)\n\nphone_numbers_2 <- phone_numbers_2 %>%\n  drop_na(main_phone)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nphone_numbers_2 %>%\n  skim()\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |Piped data |\n|Number of rows           |13109      |\n|Number of columns        |4          |\n|_______________________  |           |\n|Column type frequency:   |           |\n|character                |4          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|customer      |         0|          1.00|   3|  99|     0|    13109|          0|\n|main_phone    |         0|          1.00|   2|  14|     0|     3106|          0|\n|main_email    |      1243|          0.91|   3|  68|     0|     2560|          0|\n|main_phone_e  |         0|          1.00|   2|  20|     0|     3107|          0|\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}